{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Embarisingly Parallel for loops using Joblib\n",
    "Example from documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "[sqrt(i ** 2) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "Parallel(n_jobs=2)(delayed(sqrt)(i ** 2) for i in range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The progress meter: the higher the value of verbose, the more messages:\n",
    "If verbose > 50 then message a for every task is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    4.9s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   10.0s finished\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from joblib import Parallel, delayed\n",
    "# n_jobs=1 turns off the parallel code for debuging.\n",
    "r = Parallel(n_jobs=1, verbose=1)(delayed(sleep)(.1) for _ in range(100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  24 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    5.0s finished\n"
     ]
    }
   ],
   "source": [
    "r = Parallel(n_jobs=2, verbose=5)(delayed(sleep)(.1) for _ in range(100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1037s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.6s finished\n"
     ]
    }
   ],
   "source": [
    "r = Parallel(n_jobs=-1, verbose=10)(delayed(sleep)(.1) for _ in range(100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the same code on the simple sleep function shows the effect of increasing the number of seperate jobs/processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing a pool of workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_reuse():\n",
    "    \"\"\"Test Reusing a pool of workers \"\"\"\n",
    "    with Parallel(n_jobs=2) as parallel:\n",
    "        accumulator = 0.\n",
    "        n_iter = 0\n",
    "        while accumulator < 1000:\n",
    "            results = parallel(delayed(sqrt)(accumulator + i ** 2) for i in range(5))\n",
    "            accumulator += sum(results)  # synchronization barrier\n",
    "            n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_no_reuse():\n",
    "    \"\"\"Test Showing Parallel overhead by not Reusing a pool of workers\"\"\"\n",
    "    accumulator = 0.\n",
    "    n_iter = 0\n",
    "    while accumulator < 1000:\n",
    "        results = Parallel(n_jobs=2)(delayed(sqrt)(accumulator + i ** 2) for i in range(5))\n",
    "        accumulator += sum(results)  # synchronization barrier\n",
    "        n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 120 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit test_reuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.68 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit test_no_reuse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Generators:\n",
    "Similar to comprehension lists but is effeicent with memory. When you create a comprehension list you need to store it in memory. This can be a problem if you use very large arrays.\n",
    "\n",
    "The generator only creates one value at a time and then when it has used that value it forgets about it. Thus saving memory. As a result they can be used for iteration but only once.\n",
    "You create a generator by using normal brackets \"()\" instead of square brackets \"[]\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 36, 81]\n",
      "0\n",
      "9\n",
      "36\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "List = [x ** 2 for x in range(10) if (x%3) is 0]\n",
    "print(List)\n",
    "for val in List:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x7f9484065fa0>\n",
      "0\n",
      "9\n",
      "36\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "gen = (x ** 2 for x in range(10) if (x%3) is 0)\n",
    "print(gen)\n",
    "for val in gen:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another-iteration\n",
      "[0, 9, 36, 81]\n",
      "0\n",
      "9\n",
      "36\n",
      "81\n",
      "<generator object <genexpr> at 0x7f9484065fa0>\n"
     ]
    }
   ],
   "source": [
    "print(\"Another-iteration\") \n",
    "print(List)\n",
    "for val in List:\n",
    "    print(val)\n",
    "    \n",
    "# Re-iteration of generator does not return any more values\n",
    "print(gen)    \n",
    "for val in gen:\n",
    "    print(val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large arrays it may be more effeicent to create a generator function more than once instead of have a large list saved in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Processing thought example\n",
    "\n",
    "Say you had many files that needed information out of or some processing/transformation.\n",
    "Say you wanted to extract some information from each of the files e.g. the time, coordinates, some other header information\n",
    "Or you wanted to normalize spectra (spectra.fits) and save the result to a new file (spectra_normalised.fits)\n",
    "\n",
    "If all the files (input and output) are independant and your processing automatic then you would probably loop over the files. This should be able to be parallelized.\n",
    "\n",
    "### Warning nested parallel processes are probably not a good idea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1/2 Code 1/2 Psudocode for many file example:\n",
    "filenames = [\"file1.txt\", \"file2.txt\", ...., \"fileN.txt\"]\n",
    "#Serial example\n",
    "for fname in filenames:\n",
    "    # Open file and load in data\n",
    "    with open(fname,\"r\") as f:\n",
    "        # Read in data\n",
    "        data = f.readlines()\n",
    "    # Do task\n",
    "    ans = calculations(data)\n",
    "    \n",
    "    #Exctract some information and/or # Save to a file\n",
    "    with open(savefile, \"w\") as g:\n",
    "        # Output to file\n",
    "        g.write(ans)\n",
    "        \n",
    "    return ans\n",
    "\n",
    "\n",
    "# Turn the code inside the loop into its own function\n",
    "def file_processing(filename, *args):\n",
    "     # Open file and load in data\n",
    "    with open(fname,\"r\") as f:\n",
    "        # Read in data\n",
    "        data = f.readlines()\n",
    "    # Do task\n",
    "    ans = calculations(data)\n",
    "    \n",
    "    #Exctract some information and/or # Save to a file\n",
    "    with open(savefile, \"w\") as g:\n",
    "        # Output to file\n",
    "        g.write(ans)\n",
    "        \n",
    "    return ans\n",
    "\n",
    "\n",
    "# Serial example with function  \n",
    "for fname in filenames:\n",
    "    file_processing(filename, *args)\n",
    "# or as comprehension list\n",
    "[file_processing(fname, *args) for fname in filenames]\n",
    "\n",
    "\n",
    "# Parallel with joblib.\n",
    "Parallel(n_jobs=2)(delayed(file_processing)(fname, *args) for fname in filenames)\n",
    "\n",
    "# If you need to then you can write code to extract the results from all the separate savefiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Example\n",
    "Convolution without loss of information from interpolation because we don't interpolate to equidistant wavelenght points. \n",
    "\n",
    "Adapted from code from Pedro Figueira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off define some functions needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def wav_selector(wav, flux, wav_min, wav_max):\n",
    "    \"\"\"\n",
    "    function that returns wavelength and flux withn a giving range\n",
    "    \"\"\"    \n",
    "    wav_sel = np.array([value for value in wav if(wav_min < value < wav_max)], dtype=\"float64\")\n",
    "    flux_sel = np.array([value[1] for value in zip(wav,flux) if(wav_min < value[0] < wav_max)], dtype=\"float64\")\n",
    "    \n",
    "    return [wav_sel, flux_sel]\n",
    "\n",
    "\n",
    "def unitary_Gauss(x, center, FWHM):\n",
    "    \"\"\"\n",
    "    Gaussian_function of area=1\n",
    "\n",
    "    p[0] = A;\n",
    "    p[1] = mean;\n",
    "    p[2] = FWHM;\n",
    "    \"\"\"\n",
    "    \n",
    "    sigma = np.abs(FWHM) /( 2 * np.sqrt(2 * np.log(2)) );\n",
    "    Amp = 1.0 / (sigma*np.sqrt(2*np.pi))\n",
    "    tau = -((x - center)**2) / (2*(sigma**2))\n",
    "    result = Amp * np.exp( tau );\n",
    "    \n",
    "    return result\n",
    "\n",
    "def chip_selector(wav, flux, chip):\n",
    "    chip = str(chip)\n",
    "    if(chip in [\"ALL\", \"all\", \"\",\"0\"]):\n",
    "        chipmin = float(hdr1[\"HIERARCH ESO INS WLEN STRT1\"])  # Wavelength start on detector [nm]\n",
    "        chipmax = float(hdr1[\"HIERARCH ESO INS WLEN END4\"])   # Wavelength end on detector [nm]\n",
    "        #return [wav, flux]\n",
    "    elif(chip == \"1\"):\n",
    "        chipmin = float(hdr1[\"HIERARCH ESO INS WLEN STRT1\"])  # Wavelength start on detector [nm]\n",
    "        chipmax = float(hdr1[\"HIERARCH ESO INS WLEN END1\"])   # Wavelength end on detector [nm]\n",
    "    elif(chip == \"2\"):\n",
    "        chipmin = float(hdr1[\"HIERARCH ESO INS WLEN STRT2\"])  # Wavelength start on detector [nm]\n",
    "        chipmax = float(hdr1[\"HIERARCH ESO INS WLEN END2\"])   # Wavelength end on detector [nm]\n",
    "    elif(chip == \"3\"):   \n",
    "        chipmin = float(hdr1[\"HIERARCH ESO INS WLEN STRT3\"])  # Wavelength start on detector [nm]\n",
    "        chipmax = float(hdr1[\"HIERARCH ESO INS WLEN END3\"])   # Wavelength end on detector [nm]\n",
    "    elif(chip == \"4\"):   \n",
    "        chipmin = float(hdr1[\"HIERARCH ESO INS WLEN STRT4\"])  # Wavelength start on detector [nm]\n",
    "        chipmax = float(hdr1[\"HIERARCH ESO INS WLEN END4\"])   # Wavelength end on detector [nm]\n",
    "    elif(chip == \"Joblib_small\"):   \n",
    "        chipmin = float(2118)  # Wavelength start on detector [nm]\n",
    "        chipmax = float(2119)  # Wavelength end on detector [nm]\n",
    "    elif(chip == \"Joblib_large\"):   \n",
    "        chipmin = float(2149)  # Wavelength start on detector [nm]\n",
    "        chipmax = float(2157)  # Wavelength end on detector [nm]\n",
    "    else:\n",
    "        print(\"Unrecognized chip tag.\")\n",
    "        exit()\n",
    "    \n",
    "    #select values form the chip  \n",
    "    wav_chip, flux_chip = wav_selector(wav, flux, chipmin, chipmax)\n",
    "    \n",
    "    return [wav_chip, flux_chip]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial version of convolution\n",
    "The computationally heavy part is the for loop over each wavelenght value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def convolution_serial(wav, flux, chip, R, FWHM_lim=5.0, plot=True):\n",
    "    \"\"\"Convolution code adapted from pedros code\"\"\"\n",
    "    \n",
    "    wav_chip, flux_chip = chip_selector(wav, flux, chip)\n",
    "    #we need to calculate the FWHM at this value in order to set the starting point for the convolution\n",
    " \n",
    "    FWHM_min = wav_chip[0]/R    #FWHM at the extremes of vector\n",
    "    FWHM_max = wav_chip[-1]/R       \n",
    "    \n",
    "    \n",
    "    #wide wavelength bin for the resolution_convolution\n",
    "    wav_extended, flux_extended = wav_selector(wav, flux, wav_chip[0]-FWHM_lim*FWHM_min, wav_chip[-1]+FWHM_lim*FWHM_max) \n",
    "    wav_extended = np.array(wav_extended, dtype=\"float64\")\n",
    "    flux_extended = np.array(flux_extended, dtype=\"float64\")\n",
    "    \n",
    "    print(\"Starting the Resolution convolution...\")\n",
    "    \n",
    "    flux_conv_res = []\n",
    "    counter = 0    \n",
    "    for wav in wav_chip:\n",
    "        # select all values such that they are within the FWHM limits\n",
    "        FWHM = wav/R\n",
    "        #print(\"FWHM of {0} calculated for wavelength {1}\".format(FWHM, wav))\n",
    "        indexes = [ i for i in range(len(wav_extended)) if ((wav - FWHM_lim*FWHM) < wav_extended[i] < (wav + FWHM_lim*FWHM))]\n",
    "        flux_2convolve = flux_extended[indexes[0]:indexes[-1]+1]\n",
    "        IP = unitary_Gauss(wav_extended[indexes[0]:indexes[-1]+1], wav, FWHM)\n",
    "        flux_conv_res.append(np.sum(IP*flux_2convolve))\n",
    "        if(len(flux_conv_res)%(len(wav_chip)//100 ) == 0):\n",
    "            counter = counter+1\n",
    "            print(\"Resolution Convolution at {}%%...\".format(counter))\n",
    "    flux_conv_res = np.array(flux_conv_res, dtype=\"float64\")\n",
    "    print(\"Done.\\n\")\n",
    "    \n",
    "    if(plot):\n",
    "        fig=plt.figure(1)\n",
    "        plt.xlabel(r\"wavelength [ $\\mu$m ])\")\n",
    "        plt.ylabel(r\"flux [counts] \")\n",
    "        plt.plot(wav_chip, flux_chip/np.max(flux_chip), color ='k', linestyle=\"-\", label=\"Original spectra\")\n",
    "        plt.plot(wav_chip, flux_conv_res/np.max(flux_conv_res), color ='b', linestyle=\"-\", label=\"Spectrum observed at and R=%d .\" % (R))\n",
    "        plt.legend(loc='best')\n",
    "        plt.show() \n",
    "    return wav_chip, flux_conv_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Parallel version of convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function around bottleneck\n",
    "def convolve(wav, R, wav_extended, flux_extended, FWHM_lim):\n",
    "        # select all values such that they are within the FWHM limits\n",
    "        FWHM = wav/R\n",
    "        indexes = [ i for i in range(len(wav_extended)) if ((wav - FWHM_lim*FWHM) < wav_extended[i] < (wav + FWHM_lim*FWHM))]\n",
    "        flux_2convolve = flux_extended[indexes[0]:indexes[-1]+1]\n",
    "        IP = unitary_Gauss(wav_extended[indexes[0]:indexes[-1]+1], wav, FWHM)\n",
    "        val = np.sum(IP*flux_2convolve) \n",
    "        unitary_val = np.sum(IP*np.ones_like(flux_2convolve))  # Effect of convolution onUnitary. For changing number of points\n",
    "        return val/unitary_val\n",
    "    \n",
    "def convolution_parallel(wav, flux, chip, R, FWHM_lim=5.0, n_jobs=-1, verbose=5):\n",
    "    \"\"\"Convolution code adapted from pedros code\"\"\"\n",
    "    \n",
    "    wav_chip, flux_chip = chip_selector(wav, flux, chip)\n",
    "    #we need to calculate the FWHM at this value in order to set the starting point for the convolution\n",
    "    \n",
    "    #print(wav_chip)\n",
    "    #print(flux_chip)\n",
    "    FWHM_min = wav_chip[0]/R    #FWHM at the extremes of vector\n",
    "    FWHM_max = wav_chip[-1]/R       \n",
    "    \n",
    "    #wide wavelength bin for the resolution_convolution\n",
    "    wav_extended, flux_extended = wav_selector(wav, flux, wav_chip[0]-FWHM_lim*FWHM_min, wav_chip[-1]+FWHM_lim*FWHM_max) \n",
    "    wav_extended = np.array(wav_extended, dtype=\"float64\")\n",
    "    flux_extended = np.array(flux_extended, dtype=\"float64\")\n",
    "    \n",
    "    print(\"Starting the Parallel Resolution convolution...\")\n",
    "    \n",
    "    parallel_result = Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(convolve)(wav,R,wav_extended, flux_extended,FWHM_lim) for wav in wav_chip)\n",
    "    flux_conv_res = np.array(parallel_result, dtype=\"float64\")\n",
    "    print(\"Done.\\n\")\n",
    "    \n",
    "\n",
    "    return wav_chip, flux_conv_res \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "import numpy as np\n",
    "#wl, flux = np.loadtxt(\"Joblib_tapas.txt\")  # 2117-2120 nm\n",
    "wl, flux = np.loadtxt(\"Joblib_tapas_large.txt\")  # 2145-2160 nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time a serial convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the Resolution convolution...\n",
      "Resolution Convolution at 1%%...\n",
      "Resolution Convolution at 2%%...\n",
      "Resolution Convolution at 3%%...\n",
      "Resolution Convolution at 4%%...\n",
      "Resolution Convolution at 5%%...\n",
      "Resolution Convolution at 6%%...\n",
      "Resolution Convolution at 7%%...\n",
      "Resolution Convolution at 8%%...\n",
      "Resolution Convolution at 9%%...\n",
      "Resolution Convolution at 10%%...\n",
      "Resolution Convolution at 11%%...\n",
      "Resolution Convolution at 12%%...\n",
      "Resolution Convolution at 13%%...\n",
      "Resolution Convolution at 14%%...\n",
      "Resolution Convolution at 15%%...\n",
      "Resolution Convolution at 16%%...\n",
      "Resolution Convolution at 17%%...\n",
      "Resolution Convolution at 18%%...\n",
      "Resolution Convolution at 19%%...\n",
      "Resolution Convolution at 20%%...\n",
      "Resolution Convolution at 21%%...\n",
      "Resolution Convolution at 22%%...\n",
      "Resolution Convolution at 23%%...\n",
      "Resolution Convolution at 24%%...\n",
      "Resolution Convolution at 25%%...\n",
      "Resolution Convolution at 26%%...\n",
      "Resolution Convolution at 27%%...\n",
      "Resolution Convolution at 28%%...\n",
      "Resolution Convolution at 29%%...\n",
      "Resolution Convolution at 30%%...\n",
      "Resolution Convolution at 31%%...\n",
      "Resolution Convolution at 32%%...\n",
      "Resolution Convolution at 33%%...\n",
      "Resolution Convolution at 34%%...\n",
      "Resolution Convolution at 35%%...\n",
      "Resolution Convolution at 36%%...\n",
      "Resolution Convolution at 37%%...\n",
      "Resolution Convolution at 38%%...\n",
      "Resolution Convolution at 39%%...\n",
      "Resolution Convolution at 40%%...\n",
      "Resolution Convolution at 41%%...\n",
      "Resolution Convolution at 42%%...\n",
      "Resolution Convolution at 43%%...\n",
      "Resolution Convolution at 44%%...\n",
      "Resolution Convolution at 45%%...\n",
      "Resolution Convolution at 46%%...\n",
      "Resolution Convolution at 47%%...\n",
      "Resolution Convolution at 48%%...\n",
      "Resolution Convolution at 49%%...\n",
      "Resolution Convolution at 50%%...\n",
      "Resolution Convolution at 51%%...\n",
      "Resolution Convolution at 52%%...\n",
      "Resolution Convolution at 53%%...\n",
      "Resolution Convolution at 54%%...\n",
      "Resolution Convolution at 55%%...\n",
      "Resolution Convolution at 56%%...\n",
      "Resolution Convolution at 57%%...\n",
      "Resolution Convolution at 58%%...\n",
      "Resolution Convolution at 59%%...\n",
      "Resolution Convolution at 60%%...\n",
      "Resolution Convolution at 61%%...\n",
      "Resolution Convolution at 62%%...\n",
      "Resolution Convolution at 63%%...\n",
      "Resolution Convolution at 64%%...\n",
      "Resolution Convolution at 65%%...\n",
      "Resolution Convolution at 66%%...\n",
      "Resolution Convolution at 67%%...\n",
      "Resolution Convolution at 68%%...\n",
      "Resolution Convolution at 69%%...\n",
      "Resolution Convolution at 70%%...\n",
      "Resolution Convolution at 71%%...\n",
      "Resolution Convolution at 72%%...\n",
      "Resolution Convolution at 73%%...\n",
      "Resolution Convolution at 74%%...\n",
      "Resolution Convolution at 75%%...\n",
      "Resolution Convolution at 76%%...\n",
      "Resolution Convolution at 77%%...\n",
      "Resolution Convolution at 78%%...\n",
      "Resolution Convolution at 79%%...\n",
      "Resolution Convolution at 80%%...\n",
      "Resolution Convolution at 81%%...\n",
      "Resolution Convolution at 82%%...\n",
      "Resolution Convolution at 83%%...\n",
      "Resolution Convolution at 84%%...\n",
      "Resolution Convolution at 85%%...\n",
      "Resolution Convolution at 86%%...\n",
      "Resolution Convolution at 87%%...\n",
      "Resolution Convolution at 88%%...\n",
      "Resolution Convolution at 89%%...\n",
      "Resolution Convolution at 90%%...\n",
      "Resolution Convolution at 91%%...\n",
      "Resolution Convolution at 92%%...\n",
      "Resolution Convolution at 93%%...\n",
      "Resolution Convolution at 94%%...\n",
      "Resolution Convolution at 95%%...\n",
      "Resolution Convolution at 96%%...\n",
      "Resolution Convolution at 97%%...\n",
      "Resolution Convolution at 98%%...\n",
      "Resolution Convolution at 99%%...\n",
      "Resolution Convolution at 100%%...\n",
      "Done.\n",
      "\n",
      "('Convolution time = ', 85.43922686576843)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "start = time.time()\n",
    "\n",
    "# \"Joblib_small\"  # \"Joblib_large\"\n",
    "x, y = convolution_serial(wl, flux, \"Joblib_large\", 50000, FWHM_lim=5.0, plot=False)\n",
    "  \n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print(\"Convolution time = \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time a parallel convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the Parallel Resolution convolution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2248 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 5848 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 10888 tasks      | elapsed:   18.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "\n",
      "('Convolution time = ', 25.072216033935547)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 15287 out of 15287 | elapsed:   24.9s finished\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# \"Joblib_small\", \"Joblib_large\"\n",
    "\n",
    "x_par, y_par = convolution_parallel(wl, flux, \"Joblib_large\", 50000, FWHM_lim=5.0)\n",
    "  \n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print(\"Convolution time = \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logging\n",
    "Traceback example, note how the line of the error is indicated as well as the values of the parameter passed to the function that triggered the exception, even though the traceback happens in the child process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "JoblibTypeError",
     "evalue": "JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f94973d1eb0, file \"/...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/home/jneal/...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f94973d1eb0, file \"/...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/home/jneal/...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-05-27T14:10:02.361629', u'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', u'msg_type': u'execute_request', u'session': u'A599ABCE7EC34540BD77D366D6ED8603', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['A599ABCE7EC34540BD77D366D6ED8603']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-05-27T14:10:02.361629', u'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', u'msg_type': u'execute_request', u'session': u'A599ABCE7EC34540BD77D366D6ED8603', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['A599ABCE7EC34540BD77D366D6ED8603'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-05-27T14:10:02.361629', u'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', u'msg_type': u'execute_request', u'session': u'A599ABCE7EC34540BD77D366D6ED8603', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \"\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Expr object>], cell_name='<ipython-input-31-03aeede4f6e0>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n   2830                 code = compiler(mod, cell_name, \"single\")\n-> 2831                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f9451174730, file \"<ipython-input-31-03aeede4f6e0>\", line 3>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2832                     return True\n   2833 \n   2834             # Flush softspace\n   2835             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f9451174730, file \"<ipython-input-31-03aeede4f6e0>\", line 3>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f9451174730, file \"<ipython-input-31-03aeede4f6e0>\", line 3>\n        self.user_global_ns = {'In': ['', u'from math import sqrt\\n[sqrt(i ** 2) for i in range(10)]', u'from joblib import Parallel, delayed\\nParallel...obs=2)(delayed(sqrt)(i ** 2) for i in range(10))', u'from time import sleep\\nfrom joblib import Par...bose=1)(delayed(sleep)(.1) for _ in range(100)) ', u'r = Parallel(n_jobs=2, verbose=5)(delayed(sleep)(.1) for _ in range(100)) ', u'r = Parallel(n_jobs=-1, verbose=10)(delayed(sleep)(.1) for _ in range(100)) ', u'def test_reuse():\\n    \"\"\"Test Reusing a pool ...synchronization barrier\\n            n_iter += 1', u'def test_no_reuse():\\n    \"\"\"Test Showing Para...  # synchronization barrier\\n        n_iter += 1', u\"get_ipython().magic(u'timeit test_reuse()')\", u\"get_ipython().magic(u'timeit test_no_reuse()')\", u'List = [x ** 2 for x in range(10) if (x%3) is 0]\\nprint(List)\\nfor val in List:\\n    print(val)', u'gen = (x ** 2 for x in range(10) if (x%3) is 0)\\nprint(gen)\\nfor val in gen:\\n    print(val)', u'List = [x ** 2 for x in range(10) if (x%3) is 0]\\nprint(List)\\nfor val in List:\\n    print(val)', u'gen = (x ** 2 for x in range(10) if (x%3) is 0)\\nprint(gen)\\nfor val in gen:\\n    print(val)', u'print(\"Another-iteration\") \\nprint(List)\\nfor ...nprint(gen)    \\nfor val in gen:\\n    print(val)', u'import matplotlib.pyplot as plt\\n\\ndef wav_sel...chipmax)\\n    \\n    return [wav_chip, flux_chip]', u'\\ndef convolution_serial(wav, flux, chip, R, F... plt.show() \\n    return wav_chip, flux_conv_res', u'\\ndef convolve(wav, R, wav_extended, flux_exte...n\")\\n    \\n\\n    return wav_chip, flux_conv_res ', u'# Load data\\nimport numpy as np\\nwl, flux = np...= np.loadtxt(\"Joblib_tapas.txt\")  # 2145-2160 nm', u'# Function around bottleneck\\ndef convolve(wav...n\")\\n    \\n\\n    return wav_chip, flux_conv_res ', ...], 'List': [0, 9, 36, 81], 'Out': {1: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], 2: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '_1': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '_2': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '__': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '___': '', '__builtin__': <module '__builtin__' (built-in)>, ...}\n        self.user_ns = {'In': ['', u'from math import sqrt\\n[sqrt(i ** 2) for i in range(10)]', u'from joblib import Parallel, delayed\\nParallel...obs=2)(delayed(sqrt)(i ** 2) for i in range(10))', u'from time import sleep\\nfrom joblib import Par...bose=1)(delayed(sleep)(.1) for _ in range(100)) ', u'r = Parallel(n_jobs=2, verbose=5)(delayed(sleep)(.1) for _ in range(100)) ', u'r = Parallel(n_jobs=-1, verbose=10)(delayed(sleep)(.1) for _ in range(100)) ', u'def test_reuse():\\n    \"\"\"Test Reusing a pool ...synchronization barrier\\n            n_iter += 1', u'def test_no_reuse():\\n    \"\"\"Test Showing Para...  # synchronization barrier\\n        n_iter += 1', u\"get_ipython().magic(u'timeit test_reuse()')\", u\"get_ipython().magic(u'timeit test_no_reuse()')\", u'List = [x ** 2 for x in range(10) if (x%3) is 0]\\nprint(List)\\nfor val in List:\\n    print(val)', u'gen = (x ** 2 for x in range(10) if (x%3) is 0)\\nprint(gen)\\nfor val in gen:\\n    print(val)', u'List = [x ** 2 for x in range(10) if (x%3) is 0]\\nprint(List)\\nfor val in List:\\n    print(val)', u'gen = (x ** 2 for x in range(10) if (x%3) is 0)\\nprint(gen)\\nfor val in gen:\\n    print(val)', u'print(\"Another-iteration\") \\nprint(List)\\nfor ...nprint(gen)    \\nfor val in gen:\\n    print(val)', u'import matplotlib.pyplot as plt\\n\\ndef wav_sel...chipmax)\\n    \\n    return [wav_chip, flux_chip]', u'\\ndef convolution_serial(wav, flux, chip, R, F... plt.show() \\n    return wav_chip, flux_conv_res', u'\\ndef convolve(wav, R, wav_extended, flux_exte...n\")\\n    \\n\\n    return wav_chip, flux_conv_res ', u'# Load data\\nimport numpy as np\\nwl, flux = np...= np.loadtxt(\"Joblib_tapas.txt\")  # 2145-2160 nm', u'# Function around bottleneck\\ndef convolve(wav...n\")\\n    \\n\\n    return wav_chip, flux_conv_res ', ...], 'List': [0, 9, 36, 81], 'Out': {1: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], 2: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '_1': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '_2': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '__': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '___': '', '__builtin__': <module '__builtin__' (built-in)>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/home/jneal/Phd/Codes/PC_Joblib_parrallelization/<ipython-input-31-03aeede4f6e0> in <module>()\n      1 \n      2 \n----> 3 \n      4 from heapq import nlargest\n      5 from joblib import Parallel, delayed\n      6 Parallel(n_jobs=3)(delayed(nlargest)(2, n) for n in (range(4), 'abcde', 3)) \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Fri May 27 14:10:02 2016\nPID: 3523                   Python 2.7.11: /home/jneal/anaconda2/bin/python\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function nlargest>\n        args = (2, 3)\n        kwargs = {}\n        self.items = [(<function nlargest>, (2, 3), {})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/heapq.py in nlargest(n=2, iterable=3, key=None)\n    458         if n >= size:\n    459             return sorted(iterable, key=key, reverse=True)[:n]\n    460 \n    461     # When key is none, use simpler decoration\n    462     if key is None:\n--> 463         it = izip(iterable, count(0,-1))                    # decorate\n        it = undefined\n        iterable = 3\n    464         result = _nlargest(n, it)\n    465         return map(itemgetter(0), result)                   # undecorate\n    466 \n    467     # General case, slowest method\n\nTypeError: izip argument #1 must support iteration\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJoblibTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-03aeede4f6e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mheapq\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnlargest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'abcde'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/jneal/anaconda2/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jneal/anaconda2/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibTypeError\u001b[0m: JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f94973d1eb0, file \"/...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/home/jneal/...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f94973d1eb0, file \"/...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/home/jneal/...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-05-27T14:10:02.361629', u'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', u'msg_type': u'execute_request', u'session': u'A599ABCE7EC34540BD77D366D6ED8603', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['A599ABCE7EC34540BD77D366D6ED8603']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-05-27T14:10:02.361629', u'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', u'msg_type': u'execute_request', u'session': u'A599ABCE7EC34540BD77D366D6ED8603', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['A599ABCE7EC34540BD77D366D6ED8603'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-05-27T14:10:02.361629', u'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', u'msg_type': u'execute_request', u'session': u'A599ABCE7EC34540BD77D366D6ED8603', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'CF7C816B154B4D37B3912A33FB1A01B4', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \"\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"from heapq import nlargest\\nfrom joblib import...largest)(2, n) for n in (range(4), 'abcde', 3)) \", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Expr object>], cell_name='<ipython-input-31-03aeede4f6e0>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n   2830                 code = compiler(mod, cell_name, \"single\")\n-> 2831                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f9451174730, file \"<ipython-input-31-03aeede4f6e0>\", line 3>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2832                     return True\n   2833 \n   2834             # Flush softspace\n   2835             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f9451174730, file \"<ipython-input-31-03aeede4f6e0>\", line 3>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f9451174730, file \"<ipython-input-31-03aeede4f6e0>\", line 3>\n        self.user_global_ns = {'In': ['', u'from math import sqrt\\n[sqrt(i ** 2) for i in range(10)]', u'from joblib import Parallel, delayed\\nParallel...obs=2)(delayed(sqrt)(i ** 2) for i in range(10))', u'from time import sleep\\nfrom joblib import Par...bose=1)(delayed(sleep)(.1) for _ in range(100)) ', u'r = Parallel(n_jobs=2, verbose=5)(delayed(sleep)(.1) for _ in range(100)) ', u'r = Parallel(n_jobs=-1, verbose=10)(delayed(sleep)(.1) for _ in range(100)) ', u'def test_reuse():\\n    \"\"\"Test Reusing a pool ...synchronization barrier\\n            n_iter += 1', u'def test_no_reuse():\\n    \"\"\"Test Showing Para...  # synchronization barrier\\n        n_iter += 1', u\"get_ipython().magic(u'timeit test_reuse()')\", u\"get_ipython().magic(u'timeit test_no_reuse()')\", u'List = [x ** 2 for x in range(10) if (x%3) is 0]\\nprint(List)\\nfor val in List:\\n    print(val)', u'gen = (x ** 2 for x in range(10) if (x%3) is 0)\\nprint(gen)\\nfor val in gen:\\n    print(val)', u'List = [x ** 2 for x in range(10) if (x%3) is 0]\\nprint(List)\\nfor val in List:\\n    print(val)', u'gen = (x ** 2 for x in range(10) if (x%3) is 0)\\nprint(gen)\\nfor val in gen:\\n    print(val)', u'print(\"Another-iteration\") \\nprint(List)\\nfor ...nprint(gen)    \\nfor val in gen:\\n    print(val)', u'import matplotlib.pyplot as plt\\n\\ndef wav_sel...chipmax)\\n    \\n    return [wav_chip, flux_chip]', u'\\ndef convolution_serial(wav, flux, chip, R, F... plt.show() \\n    return wav_chip, flux_conv_res', u'\\ndef convolve(wav, R, wav_extended, flux_exte...n\")\\n    \\n\\n    return wav_chip, flux_conv_res ', u'# Load data\\nimport numpy as np\\nwl, flux = np...= np.loadtxt(\"Joblib_tapas.txt\")  # 2145-2160 nm', u'# Function around bottleneck\\ndef convolve(wav...n\")\\n    \\n\\n    return wav_chip, flux_conv_res ', ...], 'List': [0, 9, 36, 81], 'Out': {1: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], 2: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '_1': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '_2': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '__': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '___': '', '__builtin__': <module '__builtin__' (built-in)>, ...}\n        self.user_ns = {'In': ['', u'from math import sqrt\\n[sqrt(i ** 2) for i in range(10)]', u'from joblib import Parallel, delayed\\nParallel...obs=2)(delayed(sqrt)(i ** 2) for i in range(10))', u'from time import sleep\\nfrom joblib import Par...bose=1)(delayed(sleep)(.1) for _ in range(100)) ', u'r = Parallel(n_jobs=2, verbose=5)(delayed(sleep)(.1) for _ in range(100)) ', u'r = Parallel(n_jobs=-1, verbose=10)(delayed(sleep)(.1) for _ in range(100)) ', u'def test_reuse():\\n    \"\"\"Test Reusing a pool ...synchronization barrier\\n            n_iter += 1', u'def test_no_reuse():\\n    \"\"\"Test Showing Para...  # synchronization barrier\\n        n_iter += 1', u\"get_ipython().magic(u'timeit test_reuse()')\", u\"get_ipython().magic(u'timeit test_no_reuse()')\", u'List = [x ** 2 for x in range(10) if (x%3) is 0]\\nprint(List)\\nfor val in List:\\n    print(val)', u'gen = (x ** 2 for x in range(10) if (x%3) is 0)\\nprint(gen)\\nfor val in gen:\\n    print(val)', u'List = [x ** 2 for x in range(10) if (x%3) is 0]\\nprint(List)\\nfor val in List:\\n    print(val)', u'gen = (x ** 2 for x in range(10) if (x%3) is 0)\\nprint(gen)\\nfor val in gen:\\n    print(val)', u'print(\"Another-iteration\") \\nprint(List)\\nfor ...nprint(gen)    \\nfor val in gen:\\n    print(val)', u'import matplotlib.pyplot as plt\\n\\ndef wav_sel...chipmax)\\n    \\n    return [wav_chip, flux_chip]', u'\\ndef convolution_serial(wav, flux, chip, R, F... plt.show() \\n    return wav_chip, flux_conv_res', u'\\ndef convolve(wav, R, wav_extended, flux_exte...n\")\\n    \\n\\n    return wav_chip, flux_conv_res ', u'# Load data\\nimport numpy as np\\nwl, flux = np...= np.loadtxt(\"Joblib_tapas.txt\")  # 2145-2160 nm', u'# Function around bottleneck\\ndef convolve(wav...n\")\\n    \\n\\n    return wav_chip, flux_conv_res ', ...], 'List': [0, 9, 36, 81], 'Out': {1: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], 2: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '_1': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '_2': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '__': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], '___': '', '__builtin__': <module '__builtin__' (built-in)>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/home/jneal/Phd/Codes/PC_Joblib_parrallelization/<ipython-input-31-03aeede4f6e0> in <module>()\n      1 \n      2 \n----> 3 \n      4 from heapq import nlargest\n      5 from joblib import Parallel, delayed\n      6 Parallel(n_jobs=3)(delayed(nlargest)(2, n) for n in (range(4), 'abcde', 3)) \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Fri May 27 14:10:02 2016\nPID: 3523                   Python 2.7.11: /home/jneal/anaconda2/bin/python\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function nlargest>\n        args = (2, 3)\n        kwargs = {}\n        self.items = [(<function nlargest>, (2, 3), {})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/home/jneal/anaconda2/lib/python2.7/heapq.py in nlargest(n=2, iterable=3, key=None)\n    458         if n >= size:\n    459             return sorted(iterable, key=key, reverse=True)[:n]\n    460 \n    461     # When key is none, use simpler decoration\n    462     if key is None:\n--> 463         it = izip(iterable, count(0,-1))                    # decorate\n        it = undefined\n        iterable = 3\n    464         result = _nlargest(n, it)\n    465         return map(itemgetter(0), result)                   # undecorate\n    466 \n    467     # General case, slowest method\n\nTypeError: izip argument #1 must support iteration\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "from joblib import Parallel, delayed\n",
    "Parallel(n_jobs=3)(delayed(nlargest)(2, n) for n in (range(4), 'abcde', 3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Joblibs Other tools\n",
    "\n",
    "## Memory\n",
    "Example from Joblib documentation showing the caching of input and outputs of the function sqaure().\n",
    "\n",
    "When it is called with the same parameters again it jsut returns the result without recomputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "mem = Memory(cachedir='/tmp/joblib')\n",
    "import numpy as np\n",
    "a = np.vander(np.arange(101)).astype(np.float)\n",
    "b = np.vander(np.arange(5)).astype(np.float)\n",
    "square = mem.cache(np.square)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling square...\n",
      "square(array([[ 0., ...,  1.],\n",
      "       ..., \n",
      "       [ 0., ...,  1.]]))\n",
      "___________________________________________________________square - 0.1s, 0.0min\n"
     ]
    }
   ],
   "source": [
    "c = square(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling square...\n",
      "square(array([[   0.,    0.,    0.,    0.,    1.],\n",
      "       [   1.,    1.,    1.,    1.,    1.],\n",
      "       [  16.,    8.,    4.,    2.,    1.],\n",
      "       [  81.,   27.,    9.,    3.,    1.],\n",
      "       [ 256.,   64.,   16.,    4.,    1.]]))\n",
      "___________________________________________________________square - 0.0s, 0.0min\n"
     ]
    }
   ],
   "source": [
    "d = square(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = square(a) # Does not recomute square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = square(b) # Does not recomute square(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing these calls to square shows that the second call of the function with the same inputs give a much faster result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistance\n",
    "joblib.dump() and joblib.load() provide a replacement for pickle to work efficiently on Python objects containing large data, in particular large numpy arrays.\n",
    "\n",
    "Filename is important here, .pkl will make a pickle like persistance\n",
    "where as .mmap with make a memory map location for parallel process shared access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "savedir = mkdtemp()\n",
    "import os\n",
    "#filename = os.path.join(savedir, 'test.pkl')      # Pickle version  \n",
    "filename = os.path.join(savedir, 'test.mmap')      # Memmap version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Then we create an object to be persisted:\n",
    "import numpy as np\n",
    "#to_persist = [('a', [1, 2, 3]), ('b', np.arange(10))]\n",
    "to_persist = np.ones(int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpUFOw5a/test.mmap', '/tmp/tmpUFOw5a/test.mmap_01.npy']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which we save into savedir:\n",
    "import joblib\n",
    "joblib.dump(to_persist, filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can then load the object from the file:\n",
    "#joblib.load(filename)\n",
    "pointer = joblib.load(filename, mmap_mode='r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
