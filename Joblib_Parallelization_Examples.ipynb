{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embarisingly Parallel for loops using Joblib\n",
    "Example from documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "[sqrt(i ** 2) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "Parallel(n_jobs=2)(delayed(sqrt)(i ** 2) for i in range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The progress meter: the higher the value of verbose, the more messages:\n",
    "If verbose > 50 then message a for every task is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    4.8s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   10.0s finished\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from joblib import Parallel, delayed\n",
    "# n_jobs=1 turns off the parallel code for debuging.\n",
    "r = Parallel(n_jobs=1, verbose=1)(delayed(sleep)(.1) for _ in range(100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    5.7s finished\n"
     ]
    }
   ],
   "source": [
    "r = Parallel(n_jobs=2, verbose=5)(delayed(sleep)(.1) for _ in range(100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "r = Parallel(n_jobs=-1, verbose=10)(delayed(sleep)(.1) for _ in range(100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the same code on the simple sleep function shows the effect of increasing the number of seperate jobs/processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing a pool of workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_reuse():\n",
    "    \"\"\"Test Reusing a pool of workers \"\"\"\n",
    "    with Parallel(n_jobs=2) as parallel:\n",
    "        accumulator = 0.\n",
    "        n_iter = 0\n",
    "        while accumulator < 1000:\n",
    "            results = parallel(delayed(sqrt)(accumulator + i ** 2) for i in range(5))\n",
    "            accumulator += sum(results)  # synchronization barrier\n",
    "            n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_no_reuse():\n",
    "    \"\"\"Test Showing Parallel overhead by not Reusing a pool of workers\"\"\"\n",
    "    accumulator = 0.\n",
    "    n_iter = 0\n",
    "    while accumulator < 1000:\n",
    "        results = Parallel(n_jobs=2)(delayed(sqrt)(accumulator + i ** 2) for i in range(5))\n",
    "        accumulator += sum(results)  # synchronization barrier\n",
    "        n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.85 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 1.46 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit test_reuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_no_reuse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Generators:\n",
    "Similar to comprehension lists but is effeicent with memory. When you create a comprehension list you need to store it in memory. This can be a problem if you use very large arrays.\n",
    "\n",
    "The generator only creates one value at a time and then when it has used that value it forgets about it. Thus saving memory. As a result they can be used for iteration but only once.\n",
    "You create a generator by using normal brackets \"()\" instead of square brackets \"[]\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "List = [x ** 2 for x in range(10) if (x%3) is 0]\n",
    "print(List)\n",
    "for val in List:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = (x ** 2 for x in range(10) if (x%3) is 0)\n",
    "print(gen)\n",
    "for val in gen:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Another-iteration\") \n",
    "print(List)\n",
    "for val in List:\n",
    "    print(val)\n",
    "    \n",
    "# Re-iteration of generator does not return any more values\n",
    "print(gen)    \n",
    "for val in gen:\n",
    "    print(val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large arrays it may be more effeicent to create a generator function more than once instead of have a large list saved in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Processing thought example\n",
    "\n",
    "Say you had many files that needed information out of or some processing/transformation.\n",
    "Say you wanted to extract some information from each of the files e.g. the time, coordinates, some other header information\n",
    "Or you wanted to normalize spectra (spectra.fits) and save the result to a new file (spectra_normalised.fits)\n",
    "\n",
    "If all the files (input and output) are independant and your processing automatic then you would probably loop over the files. This should be able to be parallelized.\n",
    "\n",
    "### Warning nested parallel processes are probably not a good idea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1/2 Code 1/2 Psudocode for many file example:\n",
    "filenames = [\"file1.txt\", \"file2.txt\", ...., \"fileN.txt\"]\n",
    "#Serial example\n",
    "for fname in filenames:\n",
    "    # Open file and load in data\n",
    "    with open(fname,\"r\") as f:\n",
    "        # Read in data\n",
    "        data = f.readlines()\n",
    "    # Do task\n",
    "    ans = calculations(data)\n",
    "    \n",
    "    #Exctract some information and/or # Save to a file\n",
    "    with open(savefile, \"w\") as g:\n",
    "        # Output to file\n",
    "        g.write(ans)\n",
    "        \n",
    "    return ans\n",
    "\n",
    "\n",
    "# Turn the code inside the loop into its own function\n",
    "def file_processing(filename, *args):\n",
    "     # Open file and load in data\n",
    "    with open(fname,\"r\") as f:\n",
    "        # Read in data\n",
    "        data = f.readlines()\n",
    "    # Do task\n",
    "    ans = calculations(data)\n",
    "    \n",
    "    #Exctract some information and/or # Save to a file\n",
    "    with open(savefile, \"w\") as g:\n",
    "        # Output to file\n",
    "        g.write(ans)\n",
    "        \n",
    "    return ans\n",
    "\n",
    "\n",
    "# Serial example with function  \n",
    "for fname in filenames:\n",
    "    file_processing(filename, *args)\n",
    "# or as comprehension list\n",
    "[file_processing(fname, *args) for fname in filenames]\n",
    "\n",
    "\n",
    "# Parallel with joblib.\n",
    "Parallel(n_jobs=2)(delayed(file_processing)(fname, *args) for fname in filenames)\n",
    "\n",
    "# If you need to then you can write code to extract the results from all the separate savefiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Joblibs Other tools\n",
    "\n",
    "## Memory\n",
    "Example from Joblib documentation showing the caching of input and outputs of the function sqaure().\n",
    "\n",
    "When it is called with the same parameters again it jsut returns the result without recomputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "mem = Memory(cachedir='/tmp/joblib')\n",
    "import numpy as np\n",
    "a = np.vander(np.arange(10001)).astype(np.float)\n",
    "b = np.vander(np.arange(5)).astype(np.float)\n",
    "square = mem.cache(np.square)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time c = square(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time d = square(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time e = square(a) # Does not recomute square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time f = square(b) # Does not recomute square(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing these calls to square shows that the second call of the function with the same inputs give a much faster result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistance\n",
    "joblib.dump() and joblib.load() provide a replacement for pickle to work efficiently on Python objects containing large data, in particular large numpy arrays.\n",
    "\n",
    "Filename is important here, .pkl will make a pickle like persistance\n",
    "where as .mmap with make a memory map location for parallel process shared access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "savedir = mkdtemp()\n",
    "import os\n",
    "filename = os.path.join(savedir, 'test.pkl')\n",
    "#filename = os.path.join(savedir, 'test.mmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Then we create an object to be persisted:\n",
    "import numpy as np\n",
    "to_persist = [('a', [1, 2, 3]), ('b', np.arange(10))]\n",
    "#to_persist = np.ones(int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#which we save into savedir:\n",
    "import joblib\n",
    "joblib.dump(to_persist, filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can then load the object from the file:\n",
    "joblib.load(filename)\n",
    "#joblib.load(filename, mmap_mode='r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
